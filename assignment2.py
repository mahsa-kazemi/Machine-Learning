
# coding: utf-8

# # Assignment 2
# 
# * This assignment includes some tests to help you make sure that your implementation is correct.  When you see a cell with `assert` commands, these are tests.
# 
# * Once you have completed the assignment, delete the cells which have these `assert` commands.  You will not need them.
# 
# * When you are done and have answered all the questions, convert this notebook to a .py file using `File > Download as > Python (.py)`.  Name your submission `assignment2.py` and submit it to OWL.
# 

# In[1]:


#It's dangerous to go alone.  Take these!
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.optimize import minimize
from scipy.special import factorial
from scipy.stats import linregress
from scipy.special import gammaln
from scipy.stats import poisson
import scipy.optimize as so
from IPython.display import display
import statsmodels.api as sm
import statsmodels.formula.api as smf
import pytest


# ## Maximum Likelihood
# 
# The poisson distribution https://en.wikipedia.org/wiki/Poisson_distribution is a discrete probability distribution often used to describe count-based data, like how many snowflakes fall in a day.
# 
# If we have count data $y$ that are influenced by a covariate or feature $x$, we can used the maximum likelihood principle to develop a regression model relating $x$ to $y$.
# 
# ### Question 1
# Write a function called `poissonNegLogLikelihood` that takes a count `y` and a parameter `lam` and produces the negative log likelihood of `y` assuming that it was generated by a Poisson distribution with parameter `lam`. You may also want to use `scipy.misc.gammaln` to compute the log of a factorial.  The Gamma Function, $\Gamma(x)$, is a sort of generalized factorial, and `gammaln` efficiently computes the natural log of the Gamma Function.
# 
# It is worth noting that $\Gamma(x) \neq x!$ so it might be worth your while to do a little reading on the gamma function before implementing this function.

# In[2]:


def poissonNegLogLikelihood(lam, y):
    """
    Computes the negative log-likelihood for a Poisson random variable.

    Inputs:
    lam - float or array.  Parameter for the poisson distribution.
    y - float or array.  Observed data.

    Outputs:
    log_lik - float.  The negative log-likelihood for the data (y) with parameter (lam).

    """
    if isinstance(lam, (float,int)) and isinstance(y, (float,int)):
        
        lam = np.array([lam])
        y = np.array([y])
    if isinstance(lam, (float,int)) and not isinstance(y, (float,int)):  
        lam = np.full(len(list(y)),lam)
    if isinstance(y, (float,int)) and not isinstance(lam, (float,int)):
        y = np.full(len(list(lam)),y)
    if lam.size ==1:
        lam = np.full(len(list(y)),lam[0])
      
    y_in = y
    index_for_ones = len(list(y_in))
    array_of_ones = np.full(index_for_ones,1)
    y_modified = y_in + array_of_ones
    lam_log = np.log(lam)
    y_times_lambda = y.T@lam_log
    lam_sum = np.sum(lam)
    log_lik = y_times_lambda - lam_sum  - np.sum(gammaln(y_modified))
    return -log_lik

#poissonNegLogLikelihood(np.array([24, 13]), np.array([1, 3]))


# ### Tests
# 
# One of the comments we recieved from the first assignment is that there were few obvious ways to check if the function you've written is working correctly.  This is an approach to address those concerns!
# 
# Now that you've written the `poissonNegLogLikelihood`, let's test to see if it works.  Below are 3 `assert` statements.  They return nothing if your implementation does what it is supposed to do and raise an error if there is an error.  If you can run this cell and don't see an `AssertionError`, your implementation produces numbers when it's supposed to and does not produce numbers when it isn't supposed to (the tests say nothing about whether the numbers are correct.)

# In[3]:





# Here are some more tests that check the values your function produces.  These are graded tests, but you can see what the answer should be ahead of time.  There are also some tests that are not shown to you at the moment.  If your `poissonNegLogLikelihood` is working, then this cell should run without any errors.
# 
# Once you are satisfied with your implementation of `poissonLogLikelihood`, please delete the cell below.

# ### Question 2
# 
# Write a function called `poissonMLE` which accepts as it's first argument an array of data `data` and returns the maximum likelihood estimate for a poisson distribution $\lambda$.  You should use `scipy.optimize.minimize`. You don't have to calculate gradients for this example.

# In[3]:


def poisson_mle(data):
    """
    Compute the maximum likelihood estimate (mle) for a poisson distribution given data.

    Inputs:
    data - float or array.  Observed data.

    Outputs:
    lambda_mle - float.  The mle for poisson distribution.
    """

    lambda_mle_min = so.minimize(poissonNegLogLikelihood, 1, args=(data), method="Powell")
    lambda_mle = lambda_mle_min.x.item()
    return lambda_mle
#poisson_mle(np.array([1,3,4]))


# Again, here are some tests for `poisson_mle`.  If you pass these tests, then that should mean your function is working.  You can also write your own tests to make sure the function is working.  Once you are happy with your implmentation, please delete the cell below.

# In[7]:





# ### Question 3
# 
# Write a function called `poissonRegressionLogLikelihood` that takes a vector $\mathbf{y}$ of counts, a design matrix $\mathbf{X}$ of features for each count (including a column of 1s for the intercept), and a vector $\mathbf{b}$ of parameters. The function should compute the likelihood of this dataset, assuming that each $y$ is independently distributed with a poisson distribution with parameter $\lambda = exp(X\beta)$.  That is to say, your function should work in the general case for $n$ obervations and $p$ parameters.
# 
# Hint: You can use `poissonNegLogLikelihood` in this answer!

# In[4]:


def poissonRegressionNegLogLikelihood(b, X, y):
    """
    Computes the negative log-likelihood for a poisson regression.

    Inputs:
    b - array.  Coefficients for the poisson regression
    X - array.  Design matrix.
    y - array.  Observed outcomes.

    Outputs:
    log_lik - float.  Negative log likelihood for the poisson regression with coefficients b.

    """
    yp = np.exp(X@b)
    log_lik= poissonNegLogLikelihood(yp, y)   
    return log_lik
#poissonRegressionNegLogLikelihood(np.array([1,2,3]), np.array([[1,4,5],[1,3,2]]), np.array([1,3]))


# ### Question 4
# 
# In `poissonRegressionNegLogLikelihood`, why did we apply the exponential function to the linear predictor?  What might have happened had we just passed $\lambda =X\beta$?  Enter your answer below in markdown.
# 
# To ensure lambda is positive we use lambda = exp(Xbeta) instead of lambda = Xbeta

# ### Question 5
# 
# Write a function called `fitPoissonRegression` which takes as its first argument data `x` and as its second argument outcomes `y` and returns the coefficients for a poisson regression.

# In[5]:


def fitPoissonRegression(X, y, lossfcn = poissonRegressionNegLogLikelihood):
    """
    Fits a poisson regression given data and outcomes.

    Inputs:
    X - array.  Design matrix
    y - array.  Observed outcomes

    Outputs:
    betas_est - array.  Coefficients which maximize the negative log-liklihood.
    """
    nrows,ncols = X.shape
    betas=np.zeros((ncols,1))
    RES = so.minimize(lossfcn,betas,args=(X,y))
    betas_est = RES.x
    return betas_est 
#fitPoissonRegression(np.array([[0.1,0.4,0.5],[0.1,0.3,0.2]]),np.array([1,3]),lossfcn = poissonRegressionNegLogLikelihood)


# ### Question 6
# 
# Write a function called `makePoissonRegressionPlot` which loads in the data from `poisson_regression_data.csv`, plots a scatterplot of the data, fits a poisson regression to this data, plots the model predictions over $x \in [-2,2]$, and then saves the plot under the file name `poisson_regression.png`.  

# In[10]:


def makePoissonRegressionPlot():
  
    possum_data=pd.read_csv('poisson_regression_data.csv')
    display(possum_data.head())
    fig, ax = plt.subplots(dpi = 120)
    possum_data.plot.scatter(x = 'x', 
                         y = 'y', 
                         alpha = 0.75,
                         ax = ax, label = 'Scatter Plot')
    a = possum_data.x.values
    b = possum_data.y.values
    c = fitPoissonRegression(a.reshape(1,-1),b,lossfcn = poissonRegressionNegLogLikelihood)
    lam_predicted = np.zeros(len(c))
    for i in range(len(c)):
        lam_predicted[i] = np.exp(a[i]*c[i]) 
    ax.plot(list(a),list(lam_predicted), '--r', label = 'Model Prediction' )
    plt.savefig('poisson_regression.png')
    plt.legend()
    plt.show()
makePoissonRegressionPlot()


# ### Question 7
# 
# Write a function called `makeLinearRegressionPlot`  which loads in the data from `poisson_regression_data.csv`, plots a scatterplot of the data, fits a linear regression to this data, plots the model predictions over $x \in [-2,2]$, and then saves the plot under the file name `linear_regression.png`. 

# In[26]:



def makeLinearRegressionPlot():
    possum_data=pd.read_csv('poisson_regression_data.csv')
    display(possum_data.head())
    fig, ax = plt.subplots(dpi = 120)
    possum_data.plot.scatter(x = 'x', 
                         y = 'y', 
                         alpha = 0.75,
                        ax = ax, label = 'Scatter Plot')

    X = pd.Series(possum_data['x']).values
    y = pd.Series(possum_data['y']).values
    X = sm.add_constant(X)
    results = sm.OLS(y, X).fit()
    print(results.summary())
    x = np.linspace(-2,2,101)
    y = 3.8001*x+2.3607
    ax.plot(x, y, '--r', label = 'OLS')
    plt.savefig('linear_regression.png')
    ax.legend()
    plt.show()
makeLinearRegressionPlot() 


# ### Question 8
# 
# 
# 1) Explain in 2 or 3 sentences why the coefficients from OLS are different from those from Poisson regression.
# 
# 2) Explain in 2 or 3 sentences why the predicted mean counts are different. Do you see any major problems with the predictions from OLS?
# 
# Provide your answer below in markdown
# 
# 
# 

# Linear regression is for continuous data but Poisson regression is for discrete data. In Poisson regression the predicted values belong to non-negative numbers (we use it for counting the # of evenets) whereas in linear regression we might have negative predicted value as can be seen in the second picture (the red -- line has negative y values)
# For this example R2 associated with OLS is 0.307 proving that the model does not fit data well (R2 is not close to 1)
# in OLS the residue follows normal distribuition but in Poisson regression it follows Poisson. In OLS, y is a linear function of coefficients but in Poisson, log(y) is a linear function of coefficients 
